{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import warnings # This library is used to ignore warnings, don't worry about it for now\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "c6c38c3613d5d5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exercise 1 (Fair dice)\n",
    "\n",
    "Implement a class called Die that represents a fair six-sided die. The class should have a method called roll_n that simulates rolling $n$ identical dice and returns an average of the rolls.\n",
    "\n",
    "1. Implement a function called estimate_proba(die, n) that takes a die object and an integer $n$. The function should roll $n$ identical dice 10,000 times and based on the results, estimate the probability of getting an average of 2.5 or less.  \n",
    "Calculate the probabilities of getting an average of 2.5 or less when rolling:  \n",
    "   a) 2 dice  \n",
    "   b) 10 dice  \n",
    "  \n",
    "2. What is the probability of getting a mean of $\\alpha$ or less when rolling 10 dice, for different values $\\alpha$ in the range of [0, 6]? Modify the estimate_proba function so that it can accept different $\\alpha$ values. Then, prepare a collection of data points and plot using sns.lineplot() to illustrate the relation."
   ],
   "id": "4dddd43454eb885d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2764e1be78ac45f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# You can use the following as a well-structured template for your code, or write it from scratch:\n",
    "\n",
    "class Die:\n",
    "    def __init__(self):\n",
    "        self.values = [1, 2, 3, 4, 5, 6]\n",
    "        ...\n",
    "    \n",
    "    def roll_n(self, n): # roll n identical dice and return the mean\n",
    "        ..."
   ],
   "id": "f1c60e8d4259297e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fair_die = Die() # create a fair die object\n",
    "\n",
    "def estimate_proba(die, n):\n",
    "    means = []\n",
    "    number_of_trials = 10000\n",
    "    for i in range(number_of_trials):\n",
    "        mean = die.roll_n(n)\n",
    "        ...\n",
    "    \n",
    "print('Estimated probability for 2 dice:', estimate_proba(fair_die, 2))\n",
    "print('Estimated probability for 10 dice:', estimate_proba(fair_die, 10))"
   ],
   "id": "6f101142bc23db6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exercise 2 (Unfair dice)\n",
    "\n",
    "Implement a class called UnfairDie that represents an unfair six-sided die. The class can be an extension of Die class, or you can write it from the start. The class should have a method called roll_n(n) that simulates rolling the die $n$ times and returns the mean of the rolls. The probabilities of rolling each face should be set by the user when creating a die object by passing a parameter probs, a list of six positive floats summing to one.\n",
    "1. What is the probability of rolling a mean of more than 15 and less than 25 when rolling 5 identical unfair dice?  \n",
    "The probabilities of rolling the faces 1-6 are given by a list [0.1, 0.1, 0.1, 0.25, 0.15, 0.3]. Conduct a simulation to estimate the probability. You can modify and reuse the estimate_proba function for this task."
   ],
   "id": "c42a726a0b314498"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class UnfairDie(Die):\n",
    "    def __init__(self, probs):\n",
    "        super().__init__() # call the constructor of the parent class\n",
    "        ..."
   ],
   "id": "bae248d7e56ab01d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "unfair_die = UnfairDie(probs=[0.1, 0.1, 0.1, 0.25, 0.15, 0.3]) # create an unfair die object",
   "id": "2b1677d49c0d3786",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Excercise 3 (Plotting the distribution of rolls)\n",
    "\n",
    "Implement a function called plot_rolls(die, n). It should take a die object and the number of dice to roll $n$. The function should simulate rolling $n$ dice 1000 times and plot the distribution of the means. The plot should be a histogram with the mean dice values on the x-axis and the probability on the y-axis. The plot should have 20 bins for values of x.\n",
    "\n",
    "1. How does the distribution of the means change when you increase the number of dice? Try $n=1, 2, 5, 10, 100$. What is the approximate shape of the distribution for large values of $n$?\n",
    "\n",
    "2. How does the distribution change when you use an unfair die with the following probabilities: [0.2, 0.1, 0.1, 0.2, 0.1, 0.3]? Compare the distributions for fair and unfair dice when $n=1$ and $n=1000$."
   ],
   "id": "e604f971723d2130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_rolls(die, n):\n",
    "    ...\n",
    "    \n",
    "    # plot the histogram\n",
    "    sns.set_style('white')\n",
    "    sns.set_context('talk')\n",
    "    sns.histplot(data=..., x=..., bins=20, kde=True)\n",
    "    \n",
    "plot_rolls(fair_die, 1)"
   ],
   "id": "9d6e74ea521d5a51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# *Exercise 4 (Entropy)\n",
    "\n",
    "Entropy is a measure of **uncertainity** or **randomness** in a random variable. \n",
    "You may have already heard about entropy in the context of thermodynamics, and if you did, you will probably see how those are related!\n",
    "The entropy of a discrete random variable $X$ with probability distribution $p(x)$ is defined as:\n",
    "$$H(X) = -\\sum_{x} p(x) \\log_2 p(x)$$\n",
    "Entropy is a **weighted average of the information content** of each possible value of $X$, where the weight is the **probability** of that value.\n",
    "The formula can also be written in a way which conveys the intuition behind it more clearly:\n",
    "$$H(X) = \\sum_{x} p(x) * \\log_2 \\frac{1}{p(x)}$$\n",
    "\n",
    "## Let's break it down:\n",
    "\n",
    "The term: $$\\log_2 \\frac{1}{p(x)}$$ is the **information content** or **surprisal** of the value $x$. For high probability events, such as the sun rising tomorrow or dad grabbing a beer after long day at work, the surprisal is low, with $\\log_2 \\frac{1}{p(x)} = 0$ when $p(x) = 1$. For low probability events, such as my master thesis being published in Nature, the surprisal is high, and $\\log_2 \\frac{1}{p(x)}$ goes to infinity as $p(x)\\to 0$. The graph below illustrates how the information content of an event $x$ changes for different values of $p(x)$.\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/surprisal.png\" height=\"401\">\n",
    "</center>\n",
    "<br/><br/>\n",
    "\n",
    "Now, the entropy is the **average surprisal** of the random variable weighted by the probability of event $x$, thus in the formula it is multiplied by $p(x)$. \n",
    "\n",
    "If you do not immediately see how this relates to the concept of a weighted average, note that $p(x) \\le 1$ and $\\sum_{x}{p(x)} = 1$. \n",
    "\n",
    "Hopefully, you can see that the formula for entropy satisfies some of our expectations when it comes to measuring surprisal of a random event.\n",
    "  \n",
    "Let's take a look at an example. The entropy of a fair coin, where $p(\\text{heads})=0.5$ and $p(\\text{tails})=0.5$, is 1 bit:\n",
    "$$H(\\text{coin}) = p(\\text{heads}) \\log_2\\frac{1}{p(\\text{heads})} + p(\\text{tails}) \\log_2\\frac{1}{p(\\text{tails})}$$\n",
    "$$= 0.5*\\log_2\\frac{1}{0.5} + 0.5*\\log_2\\frac{1}{0.5} = 1$$\n",
    "while a coin that always lands heads has an entropy of 0 bits:\n",
    "$$H(\\text{coin}) = 1*\\log_2\\frac{1}{1} = 0$$\n",
    "<br/><br/>\n",
    "***\n",
    "\n",
    "1. Take the Die class from the previous exercise and implement a method called entropy that calculates the entropy of the die. How does the entropy of a fair die compare to the entropy of an unfair die with the probabilities [0.1, 0.1, 0.1, 0.25, 0.15, 0.3]? Be sure to return a valid entropy value even if some of the probabilities are zero."
   ],
   "id": "33597f17f532d2a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Excercise 5 (Pachinko)\n",
    "\n",
    "Pachinko is a Japanese gambling game played on a vertical board. The board has pegs protruding from the surface and the player has to drop a ball from the top. The ball bounces off the pegs and can land in one of specially designated pockets. The pockets have different values and the prize is determined by the pocket in which the ball lands.  \n",
    "\n",
    "<br/><br/>\n",
    "<center>\n",
    "<img src=\"figures/pachinko1.jpg\" height=\"600\">\n",
    "<img src=\"figures/pachinko.png\" height=\"600\">\n",
    "</center>\n",
    "<br/><br/>\n",
    "\n",
    "The figure above shows an actual pachinko machine (left) and a simplified version of a pachinko board (right). Assume the ball has an equal chance of bouncing either left or right off each peg. \n",
    "\n",
    "One can simulate the results of such a game in many ways. One example is by assigning a value of 0 to each left bounce and 1 to each right bounce. As the ball falls through $n$ rows, its final position (bin index) is determined by the sum of the values in each row.\n",
    "\n",
    "1. Create a class called Pachinko that represents a simplified pachinko board of $k$ rows. The class should have a method called drop_balls that simulates dropping $n$ balls through the board and returns the list of $n$ integers, corresponding to the final position (bin index) of each ball.\n",
    "2. Create a function called plot_pachinko. It should take a Pachinko object and the number of balls $n$ as arguments. The function should simulate dropping $n$ balls through the board and plot a histogram of the distribution of balls in all bins. The plot for a $k$-row board should have $k+1$ bins.\n",
    "3. Plot the histogram of the results of dropping 1000 balls through a pachinko board with $k=5, 10, 20$ rows. What shape does this distribution converge to as the number of rows increases?\n",
    "4. You encounter a 10-row pachinko machine. One game (equivalent of dropping one ball) costs you 10 yen. If the ball lands in either the first or last bin, you win 2500 yen. You can play as many times as you wish. Will this machine make the casino go bankrupt? Conduct a simulation to verify your prediction.\n",
    "5. Extra: Modify the Pachinko class to allow for different probabilities of bouncing left and right. How does this affect the distribution of the final positions in terms of the shape and the mean value? Plot three distributions with different probabilities of bouncing left and right to illustrate the differences."
   ],
   "id": "2b56986210fe716d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# You can use the following as a well-structured template for your code, or write it from scratch:\n",
    "\n",
    "class Pachinko:\n",
    "    def __init__(self, k):\n",
    "        self.num_rows = k\n",
    "        ...\n",
    "    \n",
    "    def drop_balls(self, n):\n",
    "        ..."
   ],
   "id": "abe83d7bc943ec96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_pachinko(pachinko, n):\n",
    "    ...\n",
    "    \n",
    "    # plot the histogram\n",
    "    sns.set_style('white')\n",
    "    sns.set_context('talk')\n",
    "    sns.histplot(data=..., x=..., bins=..., kde=True)"
   ],
   "id": "2720b41d232ddbe2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pachinko_10_rows = Pachinko(k=10)\n",
    "plot_pachinko(pachinko_10_rows, n=1000)"
   ],
   "id": "d8564e7746cef107",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
